{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from rationale_3players_sentence_classification_models import ClassifierModule, HardRationale3PlayerClassificationModel\n",
    "from rationale_3players_for_emnlp import HardRationale3PlayerClassificationModelForEmnlp\n",
    "\n",
    "import torch\n",
    "from transformers import *\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify arguments for the model and data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "DATA_FOLDER = os.path.join(\"../../sentiment_dataset/data/\")\n",
    "LABEL_COL = \"label\"\n",
    "TEXT_COL = \"sentence\"\n",
    "TO_LOWER = True\n",
    "MAX_LEN = 150\n",
    "BATCH_SIZE_PRED = 512\n",
    "TRAIN_SIZE = 0.6\n",
    "batch_size = 128\n",
    "TOKEN_CUTOFF = 75\n",
    "\n",
    "class Argument():\n",
    "    def __init__(self):\n",
    "        self.model_type = 'RNN'\n",
    "        self.cell_type = 'GRU'\n",
    "        self.hidden_dim = 400\n",
    "        self.embedding_dim = 768\n",
    "        self.kernel_size = 5\n",
    "        self.layer_num = 1\n",
    "        self.fine_tuning = False\n",
    "        self.z_dim = 2\n",
    "        self.gumbel_temprature = 0.1\n",
    "        self.cuda = True\n",
    "        self.batch_size = 40\n",
    "        self.mlp_hidden_dim = 50\n",
    "        self.dropout_rate = 0.4\n",
    "        self.use_relative_pos = True\n",
    "        self.max_pos_num = 20\n",
    "        self.pos_embedding_dim = -1\n",
    "        self.fixed_classifier = True\n",
    "        self.fixed_E_anti = True\n",
    "        self.lambda_sparsity = 3.0\n",
    "        self.lambda_continuity = 1.0\n",
    "        self.lambda_anti = 1.0\n",
    "        self.lambda_pos_reward = 0.1\n",
    "        self.exploration_rate = 0.05\n",
    "        self.highlight_percentage = 0.3\n",
    "        self.highlight_count = 8\n",
    "        self.count_tokens = 8\n",
    "        self.count_pieces = 4\n",
    "        self.lambda_acc_gap = 1.2\n",
    "        self.label_embedding_dim = 400\n",
    "        self.game_mode = '3player'\n",
    "        self.margin = 0.2\n",
    "#         self.lm_setting = 'single'\n",
    "        self.lm_setting = 'multiple'\n",
    "#         self.lambda_lm = 100.0\n",
    "        self.lambda_lm = 1.0\n",
    "        self.ngram = 4\n",
    "        self.with_lm = False\n",
    "        self.batch_size_ngram_eval = 5\n",
    "        self.lr=0.001\n",
    "        self.working_dir = '/dccstor/yum-dbqa/Rationale/structured_rationale/game_model_with_lm/beer_single_working_dir'\n",
    "        self.model_prefix = 'tmp.%s.highlight%.2f.cont%.2f'%(self.game_mode, \n",
    "                                                                             self.highlight_percentage, \n",
    "                                                                             self.lambda_continuity)\n",
    "        self.pre_trained_model_prefix = 'pre_trained_cls.model'\n",
    "\n",
    "        self.save_path = os.path.join(\"..\", \"models\")\n",
    "        self.model_prefix = \"sst2rnpmodel\"\n",
    "        self.save_best_model = True\n",
    "        self.num_labels = 2\n",
    "        \n",
    "args = Argument()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Layer\n",
    "\n",
    "We want to use the pre-trained BERT embeddings, which generates embedded word vectors from word tokens.\n",
    "\n",
    "#### Process for a single sentence\n",
    "1.) generate_tokens() takes the BERT tokenizer and a sentence and tokenizes this text, to a limit of TOKEN_CUTOFF tokens. If the number of tokens is less than TOKEN_CUTOFF, it pads the tokens with the BERT pad symbol. It also provides a mask that can be used to ignore any pad tokens in classifier models down the road.<br>\n",
    "2.) embedding_func() takes the tokens from generate_tokens and uses them to make a corresponding embedding.\n",
    "\n",
    "#### Multiple sentences\n",
    "get_all_tokens takes a pandas dataframe, and adds columns tokens and mask into that dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretrained_weights = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "model.eval()\n",
    "\n",
    "def generate_tokens(tokenizer, text):\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    tokenized_text = tokenized_text[:TOKEN_CUTOFF - 2]\n",
    "    tokenized_text = [\"[CLS]\"] + tokenized_text + [\"[SEP]\"]\n",
    "    pad_length = TOKEN_CUTOFF - len(tokenized_text)\n",
    "    mask = [1] * len(tokenized_text) + [0] * pad_length\n",
    "    \n",
    "    tokenized_text = tokenized_text + [\"[PAD]\"] * pad_length\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    \n",
    "    return np.array(indexed_tokens), np.array(mask)\n",
    "    \n",
    "def embedding_func(tokens):\n",
    "    ones_mask = Variable(torch.from_numpy(np.ones((len(tokens), TOKEN_CUTOFF))))\n",
    "    if args.cuda:\n",
    "        ones_mask = ones_mask.cuda()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(tokens, ones_mask)[0]        \n",
    "    return embeddings\n",
    "\n",
    "def get_all_tokens(data):\n",
    "    l = []\n",
    "    m = []\n",
    "    for sentence in data:\n",
    "        token_list, mask = generate_tokens(tokenizer, sentence)\n",
    "        l.append(token_list)\n",
    "        m.append(mask)\n",
    "    tokens = pd.DataFrame({\"tokens\": l, \"mask\": m})\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We read the data from files that already have it split between test and train sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fpath):\n",
    "    df_dict = {LABEL_COL: [], TEXT_COL: []}\n",
    "    with open(fpath, 'r') as f:\n",
    "        label_start = 0\n",
    "        sentence_start = 2\n",
    "        for line in f:\n",
    "            label = int(line[label_start])\n",
    "            sentence = line[sentence_start:]\n",
    "            df_dict[LABEL_COL].append(label)\n",
    "            df_dict[TEXT_COL].append(sentence)\n",
    "    return pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "df_train = load_data(os.path.join(DATA_FOLDER, 'stsa.binary.train'))\n",
    "df_test = load_data(os.path.join(DATA_FOLDER, 'stsa.binary.test'))\n",
    "\n",
    "# create training and testing labels\n",
    "y_train = df_train[LABEL_COL]\n",
    "y_test = df_test[LABEL_COL]\n",
    "\n",
    "# create training and testing inputs\n",
    "X_train = df_train[TEXT_COL]\n",
    "X_test = df_test[TEXT_COL]\n",
    "\n",
    "df_train = pd.concat([df_train, get_all_tokens(X_train)], axis=1)\n",
    "df_test = pd.concat([df_test, get_all_tokens(X_test)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v-kedere\\AppData\\Local\\Continuum\\anaconda3\\envs\\rnp_env\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "args = Argument()\n",
    "\n",
    "classification_model = HardRationale3PlayerClassificationModelForEmnlp(embedding_func, args)\n",
    "\n",
    "if args.cuda:\n",
    "    classification_model.cuda()\n",
    "\n",
    "classification_model.init_optimizers()\n",
    "classification_model.init_C_model()\n",
    "\n",
    "args.fixed_E_anti = False\n",
    "classification_model.fixed_E_anti = args.fixed_E_anti\n",
    "args.with_lm = False\n",
    "args.lambda_lm = 1.0\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "dev_accs = [0.0]\n",
    "dev_anti_accs = [0.0]\n",
    "dev_cls_accs = [0.0]\n",
    "test_accs = [0.0]\n",
    "test_anti_accs = [0.0]\n",
    "test_cls_accs = [0.0]\n",
    "best_dev_acc = 0.0\n",
    "best_test_acc = 0.0\n",
    "num_iteration = 100\n",
    "display_iteration = 1\n",
    "test_iteration = 1\n",
    "\n",
    "eval_accs = [0.0]\n",
    "eval_anti_accs = [0.0]\n",
    "\n",
    "queue_length = 200\n",
    "z_history_rewards = deque(maxlen=queue_length)\n",
    "z_history_rewards.append(0.)\n",
    "\n",
    "classification_model.init_optimizers()\n",
    "classification_model.init_rl_optimizers()\n",
    "classification_model.init_reward_queue()\n",
    "\n",
    "old_E_anti_weights = classification_model.E_anti_model.predictor._parameters['weight'][0].cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_data(batch):\n",
    "    x_mat = np.stack(batch[\"tokens\"], axis=0)\n",
    "    x_mask = np.stack(batch[\"mask\"], axis=0)\n",
    "    y_vec = np.stack(batch[\"label\"], axis=0)\n",
    "    \n",
    "    batch_x_ = Variable(torch.from_numpy(x_mat)).to(torch.int64)\n",
    "    batch_m_ = Variable(torch.from_numpy(x_mask)).type(torch.FloatTensor)\n",
    "    batch_y_ = Variable(torch.from_numpy(y_vec)).to(torch.int64)\n",
    "\n",
    "    if args.cuda:\n",
    "        batch_x_ = batch_x_.cuda()\n",
    "        batch_m_ = batch_m_.cuda()\n",
    "        batch_y_ = batch_y_.cuda()\n",
    "\n",
    "    return batch_x_, batch_m_, batch_y_\n",
    "\n",
    "def _get_sparsity(z, mask):\n",
    "    mask_z = z * mask\n",
    "    seq_lengths = torch.sum(mask, dim=1)\n",
    "\n",
    "    sparsity_ratio = torch.sum(mask_z, dim=-1) / seq_lengths #(batch_size,)\n",
    "#     sparsity_count = torch.sum(mask_z, dim=-1)\n",
    "\n",
    "    return sparsity_ratio\n",
    "\n",
    "def _get_continuity(z, mask):\n",
    "    mask_z = z * mask\n",
    "    seq_lengths = torch.sum(mask, dim=1)\n",
    "    \n",
    "    mask_z_ = torch.cat([mask_z[:, 1:], mask_z[:, -1:]], dim=-1)\n",
    "        \n",
    "    continuity_ratio = torch.sum(torch.abs(mask_z - mask_z_), dim=-1) / seq_lengths #(batch_size,) \n",
    "#     continuity_count = torch.sum(torch.abs(mask_z - mask_z_), dim=-1)\n",
    "    \n",
    "    return continuity_ratio\n",
    "\n",
    "def display_example(x, m, z):\n",
    "    seq_len = int(m.sum().item())\n",
    "    ids = x[:seq_len]\n",
    "    tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "    \n",
    "    final = \"\"\n",
    "    for i in range(1, len(tokens) - 1):\n",
    "        if z[i]:\n",
    "            final += \"[\" + tokens[i] + \"]\"\n",
    "        else:\n",
    "            final += tokens[i]\n",
    "        final += \" \"\n",
    "    print(final)\n",
    "\n",
    "def test():\n",
    "    classification_model.eval()\n",
    "    \n",
    "    test_batch = df_test.sample(100)\n",
    "    batch_x_, batch_m_, batch_y_ = generate_data(test_batch)\n",
    "    predict, anti_predict, z, neg_log_probs = classification_model(batch_x_, batch_m_)\n",
    "    \n",
    "    # do a softmax on the predicted class probabilities\n",
    "    _, y_pred = torch.max(predict, dim=1)\n",
    "    \n",
    "    # calculate sparsity\n",
    "    print(\"Test sparsity: \", _get_sparsity(z, batch_m_).sum().item() / batch_size)\n",
    "    \n",
    "    accuracy = (y_pred == batch_y_).sum().item()\n",
    "    print(\"Test accuracy: \", accuracy, \"%\")\n",
    "\n",
    "    # display an example\n",
    "    print(\"Gold Label: \", batch_y_[0].item(), \" Pred label: \", y_pred[0].item())\n",
    "    display_example(batch_x_[0], batch_m_[0], z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                 | 1/100 [00:03<06:06,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sparsity:  0.18539123237133026\n",
      "Test accuracy:  49 %\n",
      "Gold Label:  0  Pred label:  1\n",
      "dr ##ear ##y , highly annoying . . . ` some body ' will appeal to no one . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▉                                                                        | 11/100 [00:26<03:56,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sparsity:  0.1956399530172348\n",
      "Test accuracy:  63 %\n",
      "Gold Label:  1  Pred label:  1\n",
      "what kids will discover is a new [collect] [##ible] [.] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████████                                                                | 21/100 [00:48<03:21,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sparsity:  0.1972774863243103\n",
      "Test accuracy:  61 %\n",
      "Gold Label:  0  Pred label:  1\n",
      "acting , particularly by tam [##bor] [,] [almost] [makes] ` ` never again ' ' worth ##while , but - l ##rb - writer [\\] [/] director - rr ##b - sc ##hae ##ffer should [follow] his [titular] [advice] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████                                                        | 31/100 [01:10<03:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sparsity:  0.19416850805282593\n",
      "Test accuracy:  73 %\n",
      "Gold Label:  1  Pred label:  0\n",
      "this is such a high - energy movie where the drumming and the marching are [so] excellent , who cares if the story ' [s] a little weak [.] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████████▏                                               | 41/100 [01:32<02:30,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sparsity:  0.18205201625823975\n",
      "Test accuracy:  63 %\n",
      "Gold Label:  0  Pred label:  1\n",
      ". . . a weak , mani ##pu ##lative , pencil - thin story that is miraculous ##ly able to entertain anyway [.] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████████▎                                       | 51/100 [01:54<02:04,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sparsity:  0.18922418355941772\n",
      "Test accuracy:  76 %\n",
      "Gold Label:  1  Pred label:  1\n",
      "chicago [is] sophisticated , [bra] ##sh [,] [sar] [##don] ##ic , completely [joy] ##ful in its [execution] [.] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████▍                               | 61/100 [02:17<01:39,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sparsity:  0.17030000686645508\n",
      "Test accuracy:  75 %\n",
      "Gold Label:  0  Pred label:  0\n",
      "just one more collection of penis [,] breast [and] [flat] [##ule] [##nce] [gag] ##s in search of a story [.] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████████▌                       | 71/100 [02:39<01:13,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sparsity:  0.19955259561538696\n",
      "Test accuracy:  70 %\n",
      "Gold Label:  0  Pred label:  1\n",
      "notorious c . h . o . has o ##odle ##s of vulgar highlights [.] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████▌               | 81/100 [03:01<00:48,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sparsity:  0.1928156316280365\n",
      "Test accuracy:  71 %\n",
      "Gold Label:  1  Pred label:  1\n",
      "a dec ##ei ##ving ##ly simple film , one that grows in power in retro ##sp [##ect] [.] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|██████████████████████████████████████████████████████████████████▍              | 82/100 [03:03<00:43,  2.39s/it]"
     ]
    }
   ],
   "source": [
    "test_freq = 10\n",
    "\n",
    "for iteration in tqdm(range(100)):\n",
    "    classification_model.train()\n",
    "\n",
    "    # sample a batch of data\n",
    "    batch = df_train.sample(batch_size, replace=True)\n",
    "    batch_x_, batch_m_, batch_y_ = generate_data(batch)\n",
    "\n",
    "    losses, predict = classification_model.train_cls_one_step(batch_x_, batch_y_, batch_m_)\n",
    "\n",
    "    # calculate classification accuarcy\n",
    "    _, y_pred = torch.max(predict, dim=1)\n",
    "\n",
    "    acc = np.float((y_pred == batch_y_).sum().cpu().data.item()) / args.batch_size\n",
    "    train_accs.append(acc)\n",
    "    \n",
    "    if iteration % test_freq == 0:\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
